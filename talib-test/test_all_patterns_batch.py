"""
Test All Patterns Batch: ØªØ³Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ù…Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª:
1. Ù‡Ù…Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
2. Ø­Ø¯Ø§Ù‚Ù„ candles requirement Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
3. Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
4. ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: Test Team
ØªØ§Ø±ÛŒØ®: 2025-10-25
"""

import talib
import pandas as pd
import numpy as np
import json
from pathlib import Path
from datetime import datetime

# =============================================================================
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
# =============================================================================

PATTERN_INFO = {
    # âœ… Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ³Øª Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ
    "ENGULFING": {
        "name": "Engulfing",
        "talib_func": talib.CDLENGULFING,
        "category": "reversal",
    },
    "HAMMER": {
        "name": "Hammer",
        "talib_func": talib.CDLHAMMER,
        "category": "reversal",
    },
    "SHOOTINGSTAR": {
        "name": "Shooting Star",
        "talib_func": talib.CDLSHOOTINGSTAR,
        "category": "reversal",
    },
    "DOJI": {
        "name": "Doji",
        "talib_func": talib.CDLDOJI,
        "category": "reversal",
    },
    "MORNINGSTAR": {
        "name": "Morning Star",
        "talib_func": talib.CDLMORNINGSTAR,
        "category": "reversal",
    },
    "INVERTEDHAMMER": {
        "name": "Inverted Hammer",
        "talib_func": talib.CDLINVERTEDHAMMER,
        "category": "reversal",
    },

    # ğŸ†• Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    "DARKCLOUDCOVER": {
        "name": "Dark Cloud Cover",
        "talib_func": talib.CDLDARKCLOUDCOVER,
        "category": "reversal",
    },
    "EVENINGSTAR": {
        "name": "Evening Star",
        "talib_func": talib.CDLEVENINGSTAR,
        "category": "reversal",
    },
    "EVENINGDOJISTAR": {
        "name": "Evening Doji Star",
        "talib_func": talib.CDLEVENINGDOJISTAR,
        "category": "reversal",
    },
    "HARAMI": {
        "name": "Harami",
        "talib_func": talib.CDLHARAMI,
        "category": "reversal",
    },
    "HARAMICROSS": {
        "name": "Harami Cross",
        "talib_func": talib.CDLHARAMICROSS,
        "category": "reversal",
    },
    "HANGINGMAN": {
        "name": "Hanging Man",
        "talib_func": talib.CDLHANGINGMAN,
        "category": "reversal",
    },
    "PIERCINGLINE": {
        "name": "Piercing Line",
        "talib_func": talib.CDLPIERCING,
        "category": "reversal",
    },
    "MORNINGDOJISTAR": {
        "name": "Morning Doji Star",
        "talib_func": talib.CDLMORNINGDOJISTAR,
        "category": "reversal",
    },
    "THREEWHITESOLDIERS": {
        "name": "Three White Soldiers",
        "talib_func": talib.CDL3WHITESOLDIERS,
        "category": "continuation",
    },
    "THREEBLACKCROWS": {
        "name": "Three Black Crows",
        "talib_func": talib.CDL3BLACKCROWS,
        "category": "continuation",
    },
}

# =============================================================================
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
# =============================================================================

def load_btc_data():
    """Load BTC 1-hour data"""
    csv_path = Path(__file__).parent.parent / 'historical' / 'BTC-USDT' / '1hour.csv'

    if not csv_path.exists():
        print(f"âŒ ERROR: {csv_path} not found!")
        return None

    df = pd.read_csv(csv_path)
    df = df.astype({
        'open': np.float64,
        'high': np.float64,
        'low': np.float64,
        'close': np.float64,
        'volume': np.float64
    })

    return df

# =============================================================================
# ØªØ³Øª Ø§Ù„Ú¯Ùˆ
# =============================================================================

def test_pattern(df, pattern_key, pattern_info, num_samples=10):
    """
    ØªØ³Øª ÛŒÚ© Ø§Ù„Ú¯Ùˆ Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† minimum candles requirement

    Returns:
        dict: Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø´Ø§Ù…Ù„ min_lookback, min_candles, detection_rate
    """

    print(f"\n{'='*70}")
    print(f"ğŸ”¬ ØªØ³Øª Ø§Ù„Ú¯Ùˆ: {pattern_info['name']}")
    print(f"{'='*70}")

    pattern_func = pattern_info['talib_func']

    # Ø§Ø¬Ø±Ø§ÛŒ detection Ø±ÙˆÛŒ Ú©Ù„ Ø¯Ø§Ø¯Ù‡
    try:
        result = pattern_func(
            df['open'].values,
            df['high'].values,
            df['low'].values,
            df['close'].values
        )
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ TA-Lib: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ detections
    detection_indices = np.where(result != 0)[0]

    if len(detection_indices) == 0:
        print(f"âŒ Ù‡ÛŒÚ† detection Ø¯Ø± Ø¯Ø§Ø¯Ù‡ BTC Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        return {
            'success': False,
            'error': 'No detections found in BTC data'
        }

    detection_count = len(detection_indices)
    detection_rate = (detection_count / len(df)) * 100

    print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ detections: {detection_count}/{len(df)} = {detection_rate:.2f}%")

    # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµØ§Ø¯ÙÛŒ
    sample_size = min(num_samples, len(detection_indices))
    # ÙÙ‚Ø· detection Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù† Ú©Ù‡ Ø­Ø¯Ø§Ù‚Ù„ 50 Ú©Ù†Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ Ø¯Ø§Ø±Ù†Ø¯
    valid_detections = [idx for idx in detection_indices if idx >= 50]

    if len(valid_detections) == 0:
        print(f"âŒ Ù‡ÛŒÚ† detection Ø¨Ø§ Ú©Ù†Ø¯Ù„ Ú©Ø§ÙÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        return {
            'success': False,
            'error': 'No detections with enough history'
        }

    sample_indices = np.random.choice(valid_detections, min(sample_size, len(valid_detections)), replace=False)

    print(f"ğŸ² ØªØ³Øª {len(sample_indices)} detection ØªØµØ§Ø¯ÙÛŒ...")

    # ØªØ³Øª Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡
    minimum_lookbacks = []

    for det_idx in sample_indices:
        # ØªØ³Øª Ø¨Ø§ lookback Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        lookback_values = [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 20, 30]
        minimum = None

        for lookback in lookback_values:
            if lookback > det_idx:
                continue

            start_idx = det_idx - lookback
            df_test = df.iloc[start_idx:det_idx + 1].copy()

            try:
                result_test = pattern_func(
                    df_test['open'].values,
                    df_test['high'].values,
                    df_test['low'].values,
                    df_test['close'].values
                )

                if result_test[-1] != 0:
                    minimum = lookback
                    break

            except:
                pass

        if minimum is not None:
            minimum_lookbacks.append(minimum)

    # ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬
    if len(minimum_lookbacks) == 0:
        print(f"âŒ Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… minimum lookback Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒÙ…!")
        return {
            'success': False,
            'error': 'Could not find minimum lookback'
        }

    min_lookback = int(np.max(minimum_lookbacks))  # Ø¨ÛŒØ´ØªØ±ÛŒÙ† (Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø±Ø§Ù†Ù‡â€ŒØªØ±ÛŒÙ†)
    avg_lookback = float(np.mean(minimum_lookbacks))
    median_lookback = float(np.median(minimum_lookbacks))

    min_candles = min_lookback + 1

    print(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬:")
    print(f"   âœ… Ø­Ø¯Ø§Ù‚Ù„ lookback: {min_lookback}")
    print(f"   âœ… Ø­Ø¯Ø§Ù‚Ù„ Ú©Ù„ Ú©Ù†Ø¯Ù„: {min_candles}")
    print(f"   ğŸ“ˆ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† lookback: {avg_lookback:.1f}")
    print(f"   ğŸ“Š Ù…ÛŒØ§Ù†Ù‡ lookback: {median_lookback:.1f}")
    print(f"   ğŸ“‰ Detection rate: {detection_rate:.2f}%")

    return {
        'success': True,
        'min_lookback': min_lookback,
        'min_candles': min_candles,
        'avg_lookback': avg_lookback,
        'median_lookback': median_lookback,
        'detection_count': detection_count,
        'detection_rate': detection_rate,
        'total_candles': len(df),
        'samples_tested': len(minimum_lookbacks)
    }

# =============================================================================
# MAIN
# =============================================================================

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§"""

    print("="*70)
    print("ğŸ”¬ ØªØ³Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ù…Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§")
    print("="*70)
    print(f"\nğŸ“… ØªØ§Ø±ÛŒØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
    print(f"\nğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ BTC...")
    df = load_btc_data()
    if df is None:
        return

    print(f"âœ… Loaded {len(df)} BTC candles")

    # ØªØ³Øª Ù‡Ù…Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§
    results = {}
    total_patterns = len(PATTERN_INFO)

    for i, (pattern_key, pattern_info) in enumerate(PATTERN_INFO.items(), 1):
        print(f"\n\n{'#'*70}")
        print(f"# [{i}/{total_patterns}] ØªØ³Øª Ø§Ù„Ú¯Ùˆ: {pattern_info['name']}")
        print(f"{'#'*70}")

        result = test_pattern(df, pattern_key, pattern_info, num_samples=10)

        results[pattern_key] = {
            'name': pattern_info['name'],
            'category': pattern_info.get('category', 'unknown'),
            **result
        }

    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    output_file = Path(__file__).parent / 'pattern_test_results.json'

    output_data = {
        'test_date': datetime.now().isoformat(),
        'btc_candles': len(df),
        'patterns_tested': len(results),
        'results': results
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"\n\n{'='*70}")
    print(f"âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    print(f"{'='*70}")

    # Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡
    print(f"\n\n{'='*70}")
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬")
    print(f"{'='*70}")

    print(f"\n{'Pattern':<25} {'Min Candles':<15} {'Detection Rate':<15} {'Status'}")
    print("-"*70)

    for pattern_key, result in results.items():
        name = result['name']

        if result['success']:
            min_candles = result['min_candles']
            det_rate = result['detection_rate']
            status = "âœ…"
        else:
            min_candles = "N/A"
            det_rate = "N/A"
            status = "âŒ"

        print(f"{name:<25} {str(min_candles):<15} {str(det_rate) if det_rate != 'N/A' else det_rate:<15} {status}")

    # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
    successful = sum(1 for r in results.values() if r['success'])
    failed = len(results) - successful

    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:")
    print(f"   âœ… Ù…ÙˆÙÙ‚: {successful}/{len(results)}")
    print(f"   âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {failed}/{len(results)}")
    print(f"{'='*70}")

if __name__ == '__main__':
    main()
